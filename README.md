# Project Scraper Suite & Web Utilities

## Overview

This project provides a suite of Python utilities for web scraping and data extraction (primarily images and video metadata), and a powerful Node.js-based web application for searching video and GIF content. The Node.js application is generated by a comprehensive setup script and features a hybrid backend allowing for flexible scraping strategies.

## Node.js Hybrid Search Application

The primary Node.js application is generated by the `setup_hybrid_search_app.sh` script.

### `setup_hybrid_search_app.sh`

*   **Purpose:** This script bootstraps a complete Node.js web application designed for searching videos and GIFs across various platforms. It creates a project directory named `hybrid_search_app/` containing the backend server, frontend UI, core modules, and example custom scrapers.
*   **Key Features:**
    *   **Hybrid Backend (`server.js`):** The core of the application. It can be configured to use different backend strategies for fetching content:
        *   **`pornsearch` library:** Utilizes the `pornsearch` npm package for sites it supports.
        *   **Custom Scrapers:** Allows use of custom-written scraper modules (located in `hybrid_search_app/modules/custom_scrapers/`) that employ `axios` for HTTP requests and `cheerio` for HTML parsing.
    *   **Configurable Strategies:** Backend behavior can be defined via:
        *   `.env` file: For setting the global `BACKEND_STRATEGY` (e.g., `custom` or `pornsearch`).
        *   `config.json`: For setting a `defaultStrategy` and `siteOverrides` to specify strategies for individual sites, and for mapping sites to their custom scraper modules via `customScrapersMap`.
    *   **Dynamic Module Loading:** Custom scraper modules are dynamically loaded by the server based on `config.json`.
    *   **Functional Frontend (`public/index.html`):** A rich user interface built with Tailwind CSS, featuring:
        *   Search controls for query, type (video/GIF), and content source (driver).
        *   Dynamic display of search results in a card-based layout.
        *   Mouseover/focus video previews on result cards.
        *   Robust thumbnail and media loading with error fallbacks.
        *   Modal view for larger media display and source links.
        *   Pagination for navigating results.
        *   Local favorites functionality (add/remove/view).
        *   URL state management for bookmarkable searches and browser navigation.
*   **Setup and Usage:**
    1.  Ensure you have Node.js and npm installed.
    2.  Run the setup script:
        ```bash
        bash setup_hybrid_search_app.sh
        ```
        This will create the `hybrid_search_app/` directory and all necessary files.
    3.  Navigate into the project directory:
        ```bash
        cd hybrid_search_app
        ```
    4.  Install Node.js dependencies:
        ```bash
        npm install
        ```
    5.  **Configure (Optional):**
        *   Edit `.env` to set `PORT` or `BACKEND_STRATEGY`.
        *   Edit `config.json` to customize `defaultStrategy`, `siteOverrides` for specific sites, or update paths in `customScrapersMap` if you modify/add scrapers.
    6.  Run the server:
        ```bash
        npm start
        # or
        node server.js
        ```
    7.  Open the application in your web browser (typically `http://localhost:3000` or as specified by the server log).

## Python Utility Scripts

These scripts provide standalone functionalities for image scraping and video search (generating local HTML reports).

### `scrapey.py` (Enhanced Image Scraper)

*   **Purpose:** Downloads images from Bing based on user queries. It renames files, extracts detailed metadata (dimensions, format, DPI, GIF info via Pillow), saves metadata to individual JSONs, and generates a `master_image_manifest.json` for `image_viewer.html`.
*   **Usage:** `python scrapey.py` (interactive).
*   **Key Dependencies:** `bing-image-downloader`, `Pillow`, `colorama`, `tqdm`.

### `xvid.py` (Video Search Utility - Local Reports)

*   **Purpose:** Searches various adult video websites (via `pornLib`) and generates a local HTML report with results, including thumbnails and links, and features mouseover video previews. Uses rate limiting.
*   **Usage:** `python xvid.py` (interactive).
*   **Key Dependencies:** `pornLib`, `ratelimit`.

### Python Dependencies Installation

A `requirements.txt` file is provided for easy installation of all Python dependencies:
```bash
pip install -r requirements.txt
```

### Associated Files for Python Scripts

*   **`image_viewer.html`:** A local HTML page to view images listed in `master_image_manifest.json` (generated by `scrapey.py`).
*   **`b.sh`:** A utility script primarily for setting up the Python image scraping environment (`scrapey.py`, `image_viewer.html`) and installing its specific dependencies (now largely superseded by `requirements.txt` for broader Python setup).

## Project Evolution & Consolidated Scripts

This project has evolved, and several scripts have been consolidated or superseded:

*   **Python Script Consolidation:**
    *   `bimgx.py`, `scrapex.py`, and `scrape.py` were merged into the more comprehensive **`scrapey.py`**.
    *   `vid.py` was merged into **`xvid.py`**.
*   **Node.js Application Setup:**
    *   The older `neon_search_app.sh` (custom Cheerio/Axios scrapers) and `setup_porn.sh` (primarily `pornsearch` library) have been superseded by the more flexible and comprehensive **`setup_hybrid_search_app.sh`**. While `setup_hybrid_search_app.sh` reuses some structural patterns and code (like the core module concepts and some scraper logic) from the older scripts, it provides a unified and more configurable approach.

**Current Recommended Scripts:**
*   For Node.js web application: Use `setup_hybrid_search_app.sh`.
*   For Python image scraping: Use `scrapey.py`.
*   For Python video search (local HTML reports): Use `xvid.py`.
